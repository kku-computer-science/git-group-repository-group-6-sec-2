[{"paper_name":"Service priority classification using machine learning","abstract":"© 2024 Silpakorn University. All rights reserved.This article details a procedure for classifying service cases with various priority levels based on machine learning (ML). It accurately defines the priority level of each service case. The presence of imbalanced datasets in service cases poses a challenge for achieving reliable classification accuracy. To address this, the use of the synthetic minority over-sampling technique (SMOTE) was proposed as the method for balancing the datasets prior to applying the ML method. From these experimental results, an improvement in the precision of the learning process was observed, which led to better outcomes in the test sets. This improvement was measured using the efficiency metrics from the confusion matrix. The experiment involved 6,182 service cases, categorized into four levels: critical, serious, moderate, and low. These were based on test comparisons with other ML methods. The accuracy achieved in the test data was 94.37%. By employing a hybrid technique to address the imbalance in SMOTE and the support vector machine model, it was found to be more effective than the comparative term frequency-inverse document frequency model that was used in conjunction with cosine similarity, which achieved an evaluation score of 70.14%.","paper_type":"Journal","paper_subtype":"Article","paper_sourcetitle":"Science, Engineering and Health Studies","keyword":"[{\"$\":\"classification\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"imbalanced data\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"machine learning\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"SMOTE\",\"@xml:lang\":\"eng\",\"@original\":\"y\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85207239454&origin=inward","publication":null,"paper_yearpub":"2024","paper_volume":"18","paper_issue":null,"paper_citation":0,"paper_page":null,"paper_doi":"10.69598\/sehs.18.24020002","paper_funder":null,"created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:16.000000Z"},{"paper_name":"Bias-Boosted ELM for Knowledge Transfer in Brain Emotional Learning for Time Series Forecasting","abstract":"© 2013 IEEE.This paper presents the Bias-Boosted Extreme Learning Machine guided Brain Emotional Learning (B2ELM-BEL) model, a significant advancement in chaotic time series prediction that effectively incorporates knowledge transfer learning. Integrating traditional Brain Emotional Learning (BEL) with the novel Biased-ELM method, the B2ELM-BEL introduces a bias term into the output weights of Extreme Learning Machines (ELM). This addition enhances the model's predictive accuracy, proving particularly beneficial in configurations with a minimal number of hidden nodes. Our evaluation of the B2ELM-BEL model across various datasets, including complex chaotic time-series benchmarks and real-world scenarios, demonstrates its superior performance over several BEL models. It achieves lower mean RMSE, MAE, and SMAPE values, and exhibits enhanced generalizability and efficiency. The findings indicate that while the single hidden node variant of B2ELM-BEL is suitable for simpler tasks, the multi-node version is more adept at handling challenging environments. This highlights the necessity of tailoring the model to the complexity of the specific dataset being analyzed.","paper_type":"Journal","paper_subtype":"Article","paper_sourcetitle":"IEEE Access","keyword":"[{\"$\":\"bias-boosted prediction models\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"brain emotional learning (BEL)\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"Chaotic time-series forecasting\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"extreme learning machine (ELM)\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"machine learning robustness\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"transfer learning\",\"@xml:lang\":\"eng\",\"@original\":\"y\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85187010509&origin=inward","publication":null,"paper_yearpub":"2024","paper_volume":"12","paper_issue":null,"paper_citation":2,"paper_page":"35868-35898","paper_doi":"10.1109\/access.2024.3371259","paper_funder":"\"This work was supported by the Graduate Education of Computer and Information Science Interdisciplinary Research Grant from the Department of Computer Science, College of Computing, Khon Kaen University, Thailand.\"","created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T17:42:16.000000Z"},{"paper_name":"Generalized stability of artificial emotional neural network in predicting domestic power peak demand","abstract":"© 2022 Silpakorn UniversityPredicting an optimal domestic power peak demand is very important for long-term electricity construction planning as the electricity cannot be stored permanently. If the prediction can give a yield close to the actual demand, the electricity suppliers can save their construction costs and provide their customers with a lower cost of electricity. However, accurate predictions still require improvement. This work, therefore, presented the predicting problem using a modified artificial emotional neural network (AENN) based on an improved JAYA optimizer. This study also applied extreme learning machine (ELM) to compute the expanded feature in the AENN. A real case study of Thailand's power peak demand was considered, which was prepared using a rolling mechanism, to demonstrate the performance of a developed predicting model when contrasted with state-of-the-art of AENN models, artificial neural network with Levenberg-Marquardt, AENN methods based on winner-take-all approach, and improved brain emotional learning-based AENN model. Performance analyses demonstrated that the proposed model provided improvements in performance and generalized stability over the comparative models.","paper_type":"Journal","paper_subtype":"Article","paper_sourcetitle":"Science, Engineering and Health Studies","keyword":"[{\"$\":\"artificial emotional neural network\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"Domestic power peak demand\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"extreme learning machine\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"improved JAYA optimization algorithm\",\"@xml:lang\":\"eng\",\"@original\":\"y\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85148299006&origin=inward","publication":null,"paper_yearpub":"2022","paper_volume":"16","paper_issue":null,"paper_citation":1,"paper_page":null,"paper_doi":"10.14456\/sehs.2022.30","paper_funder":null,"created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:30.000000Z"},{"paper_name":"Incident Task Sequence for Service Priority using Cosine Similarity","abstract":"© 2022 IEEE.The article herein details a procedure for classifying service cases by priority level based on the service level agreement (SLA) between an organization and the customer. The main factor in the article's publication was the accuracy of the classification of the importance of internal service work. However, many service evaluators remain confused about the tiering of service cases. Therefore, creating accurate service case classification models is imperative to simplify the classification process. The service cases consisted of four levels: series, critical, moderate, and low. We employed natural language processing (NLP) to develop a more efficient priority level of service for the organization. We implemented the weighting of the term frequency - inverse document frequency (TF-IDF) method and cosine Similarity with the measuring degree concept of similarity terms within each service case. The model consisted of four processes: data collection, preprocessing, TF-IDF calculation, and similarity and scoring calculation. The model presented here improved the accuracy of the classified process and produced better results in the test sets, measuring the efficiency from the cosine similarity. Lastly, our research contained 5,790 service cases with an accuracy of 70.14%, achieved through the combination of TF-IDF and cosine similarity.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"Proceedings - 2022 1st International Conference on Technology Innovation and Its Applications, ICTIIA 2022","keyword":"[{\"$\":\"corpus\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"cosine similarity\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"priority classification\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"TF-IDF\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"word embedding\",\"@xml:lang\":\"eng\",\"@original\":\"y\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85143084524&origin=inward","publication":null,"paper_yearpub":"2022","paper_volume":null,"paper_issue":null,"paper_citation":2,"paper_page":null,"paper_doi":"10.1109\/ictiia54654.2022.9935947","paper_funder":"\"ACKNOWLEDGMENT All research-related operations were supported by the ComputerScienceDepartment,Collegeof Computing,Khon Kaen University, Khon Kaen, Thailand.\"","created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:28.000000Z"},{"paper_name":"Enhanced Local Receptive Fields based Extreme Learning Machine using Dominant Patterns Selection","abstract":"© 2021 IEEE.The local receptive fields based ELM (ELM-LRF) is an extended version of ELM. Its hidden nodes are structure through the local connection approach, which demonstrated satisfactory performance in image classification problems. However, ELM-LRF still requires further improvement because extracting images features directly with random initial weights will generate redundancy features that may degrade its performance in some situations. This paper, therefore, presents a new method named the enhanced local receptive fields based ELM using dominant patterns selection (DP-ELM-LRF) to enhance ELM-LRF, which applies novel feature selection in vehicle detection through the selection of dominant patterns of HOGs (DPHOG) for selecting dominant features in the ELM feature space. DP-ELM-LRF evaluated classification performance on GTI and Concrete Crack datasets for binary classification and MNIST, Semeion, and small NORB datasets for multi-classification. Experiment results demonstrated that the DP-ELM-LRF was superior to the ELM-LRF and other comparative methods of multi-classification, whereas binary classification, DP-ELM-LRF, remains comparable with ELM-LRF.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"ICSEC 2021 - 25th International Computer Science and Engineering Conference","keyword":"[{\"$\":\"dominant patterns selection\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"extreme learning machine\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"feature selection\",\"@xml:lang\":\"eng\",\"@original\":\"y\"},{\"$\":\"local receptive fields\",\"@xml:lang\":\"eng\",\"@original\":\"y\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85125189779&origin=inward","publication":null,"paper_yearpub":"2021","paper_volume":null,"paper_issue":null,"paper_citation":0,"paper_page":"161-166","paper_doi":"10.1109\/icsec53205.2021.9684636","paper_funder":"\"This research has been partially supported by the Department of Computer Science, Faculty of Science, Khon Kaen University, Thailand.\"","created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:16.000000Z"},{"paper_name":"An Incremental Kernel Extreme Learning Machine for Multi-Label Learning with Emerging New Labels","abstract":"© 2013 IEEE.Multi-label learning with emerging new labels is a practical problem that occurs in data streams and has become an important new research issue in the area of machine learning. However, existing models for dealing with this problem require high learning computational times, and there still exists a lack of research. Based on these issues, this paper presents an incremental kernel extreme learning machine for multi-label learning with emerging new labels, consisting of two parts: a novelty detector; and a multi-label classifier. The detector with free-user-setting threshold parameters was developed to identify instances with new labels. A new incremental multi-label classifier and its improved version were developed to predict a label set for each instance, which can add output units incrementally and update themselves in unlabeled instances. Comprehensive evaluations of the proposed method were carried out on the problems of multi-label classification with emerging new labels compared to comparative algorithms, which revealed the promising performance of the proposed method.","paper_type":"Journal","paper_subtype":"Article","paper_sourcetitle":"IEEE Access","keyword":"[{\"$\":\"class incremental learning\",\"@xml:lang\":\"eng\"},{\"$\":\"data stream classification\",\"@xml:lang\":\"eng\"},{\"$\":\"extreme learning machine\",\"@xml:lang\":\"eng\"},{\"$\":\"Multi-label classification\",\"@xml:lang\":\"eng\"},{\"$\":\"multi-label learning with emerging new labels\",\"@xml:lang\":\"eng\"},{\"$\":\"novelty detection\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85082003806&origin=inward","publication":null,"paper_yearpub":"2020","paper_volume":"8","paper_issue":null,"paper_citation":13,"paper_page":"46055-46070","paper_doi":"10.1109\/access.2020.2978648","paper_funder":"\"This work was supported by the Graduate Education of Computer and Information Science Research Grant from the Department of Computer Science, Faculty of Science, Khon Kaen University, under Grant 001\\\/2558.\"","created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:24.000000Z"},{"paper_name":"Enhancement of artificial emotional neural network using Jaya algorithm and the investigation of expanded feature selected for wind power forecasting","abstract":"© 2019 Association for Computing Machinery.The Brain Emotional Learning (BEL) is a novel bio-inspired machine learning approach mentioned as a new class of artificial neural network (ANN). The artificial emotional neural network (AENN) is one of the BEL methods which used the genetic algorithm (GA) to compute proper weights, weights of the amygdala (AMYG), orbitofrontal cortex (OFC) weights and a bias value. AENN trained by GA has been reported that it could produce low error rates. However, AENN still has more rooms to enhance its prediction of performance, especially generalization and the prediction of performance. Therefore, this paper aims to propose a new training method for AENN. The JAYA optimization algorithm optimized the weights and the biases of AENN. Two new proposed models are named as AENN-Max-JAYA and AENN-Mean-JAYA. Their names are according to the way of selecting the additional expanded feature which obtained through either the max or the average of input patterns, respectively. From the experimental results for wind power forecasting dataset, the proposed methods proved that the results are better in generalization performance and give lower error rates which compared to the comparative AENN models and traditional ANNs.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"ACM International Conference Proceeding Series","keyword":"[{\"$\":\"Artificial emotional neural network\",\"@xml:lang\":\"eng\"},{\"$\":\"Brain Emotional Learning\",\"@xml:lang\":\"eng\"},{\"$\":\"Forecasting\",\"@xml:lang\":\"eng\"},{\"$\":\"JAYA optimization algorithm\",\"@xml:lang\":\"eng\"},{\"$\":\"Wind power\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85073213623&origin=inward","publication":null,"paper_yearpub":"2019","paper_volume":null,"paper_issue":null,"paper_citation":1,"paper_page":"137-142","paper_doi":"10.1145\/3348445.3348448","paper_funder":null,"created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:30.000000Z"},{"paper_name":"Kernel extreme learning machine based on fuzzy set theory for multi-label classification","abstract":"© 2017, Springer-Verlag GmbH Germany, part of Springer Nature.Multi-label classification is a special kind of classification problem, where a single instance can be labeled to more than one class. Extreme learning machine (ELM) with kernel is an efficient method for solving both regression and multi-class classification problems. However, ELM with kernel has a limitation when it comes to multi-label classification tasks. To solve this problem, this paper proposes an enhanced ELM with kernel based on a fuzzy set theory for multi-label classification problems. The relationship between an instance and its corresponding class can be defined as the fuzzy membership. This fuzzy membership is used in output weights computation to weigh the training sample towards the corresponding classes. The experimental results demonstrate that the proposed method outperforms the ELM family of algorithms for multi-label problems, as well as the state-of-the-art multi-label classification algorithms.","paper_type":"Journal","paper_subtype":"Article","paper_sourcetitle":"International Journal of Machine Learning and Cybernetics","keyword":"[{\"$\":\"Extreme learning machine with kernel\",\"@xml:lang\":\"eng\"},{\"$\":\"Fuzzy membership\",\"@xml:lang\":\"eng\"},{\"$\":\"Fuzzy set theory\",\"@xml:lang\":\"eng\"},{\"$\":\"Multi-label classification\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85064935473&origin=inward","publication":null,"paper_yearpub":"2019","paper_volume":"10","paper_issue":"5","paper_citation":32,"paper_page":"979-989","paper_doi":"10.1007\/s13042-017-0776-3","paper_funder":"\"Acknowledgements This work was supported by the Graduate Education of Computer and Information Science Interdisciplinary Research Grant from Department of Computer Science, Khon Kaen University (Grant no. 001\\\/2558).\"","created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:21.000000Z"},{"paper_name":"Parallelized Metaheuristic-Ensemble of Heterogeneous Feedforward Neural Networks for Regression Problems","abstract":"© 2013 IEEE.A feedforward neural network ensemble trained through metaheuristic algorithms has been proposed by researchers to produce a group of optimal neural networks. This method, however, has proven to be very time-consuming during the optimization process. To overcome this limitation, we propose a metaheuristic-based learning algorithm for building an ensemble system, resulting in shorter training time. In our proposed method, a master-slave based metaheuristic algorithm is employed in the optimization process to produce a group of heterogeneous feedforward neural networks, in which the global search operations are executed on the master, and the tasks of objective evaluation are distributed to the slaves (workers). To reduce evaluation costs, the entire training dataset is randomly divided equally into several disjoint subsets. Each subset is randomly paired with another subset of the remainder and distributed to a worker for the objective evaluation. Following the optimization process, representative candidate solutions (individuals) from the entire population are selected to perform as the base components of the ensemble system. The performance of the proposed method has been compared with those of other state-of-the-art techniques in over 31 benchmark regression datasets taken from public repositories. The experimental results show that the proposed method not only reduces the computational time but also achieves significantly better prediction accuracy. Moreover, the proposed method achieved promising results in the application of a subset of the million song dataset, which identifies the release year of a song and predicts the buzz on Twitter.","paper_type":"Journal","paper_subtype":"Article","paper_sourcetitle":"IEEE Access","keyword":"[{\"$\":\"encoding scheme\",\"@xml:lang\":\"eng\"},{\"$\":\"ensemble learning\",\"@xml:lang\":\"eng\"},{\"$\":\"feedforward neural network\",\"@xml:lang\":\"eng\"},{\"$\":\"hybrid learning\",\"@xml:lang\":\"eng\"},{\"$\":\"master-slave model\",\"@xml:lang\":\"eng\"},{\"$\":\"metaheuristic optimization\",\"@xml:lang\":\"eng\"},{\"$\":\"Neural network with random weights\",\"@xml:lang\":\"eng\"},{\"$\":\"parallel computing\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85062950887&origin=inward","publication":null,"paper_yearpub":"2019","paper_volume":"7","paper_issue":null,"paper_citation":18,"paper_page":"26909-26932","paper_doi":"10.1109\/access.2019.2900563","paper_funder":"\"This work was supported by the Computer and Information Science Interdisciplinary Research Grant from the Department of Computer Science, Faculty of Science, Khon Kaen University, under Grant 002\\\/2556.\"","created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:23.000000Z"},{"paper_name":"A Fast Convolutional Denoising Autoencoder Based Extreme Learning Machine","abstract":"© 2017 IEEE.The convolutional autoencoder (CAE) was proposed on convolutional neural network (CNN) and denoising autoencoder (DAE). CAE can address the corrupted input samples and high dimensional problem. However, CAE has a shortcoming involving a large training timescale because the parameters of network are commonly tuned by gradient descent (GD) learning method. In order to alleviate this problem, this paper proposed a fast convolutional denoising autoencoder based extreme learning machine (ELM), called fast convolutional denoising autoencoder (FCDA). In FCDA, the random convolutional hidden nodes are used to reduce the dimension of input data. After that, the proposed denoising ELM autoencoder is used to reconstruct the cleaned data. The experimental results indicate that the proposed method not only speeds up the traditional CAE, but it also outperforms the CAE algorithm in terms of reconstruction error. Moreover, we applied the proposed method FCDA as the pre-processing method for ML-ELM classifier. The results illustrate the combination of the proposed FCDA, and ML-ELM achieves the classification performance better than the comparative methods.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"ICSEC 2017 - 21st International Computer Science and Engineering Conference 2017, Proceeding","keyword":"[{\"$\":\"Convolutional Autoencoder\",\"@xml:lang\":\"eng\"},{\"$\":\"Denoising Autoencoder\",\"@xml:lang\":\"eng\"},{\"$\":\"Extreme Learning Machine\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85053439894&origin=inward","publication":null,"paper_yearpub":"2018","paper_volume":null,"paper_issue":null,"paper_citation":2,"paper_page":"185-189","paper_doi":"10.1109\/icsec.2017.8443962","paper_funder":"\"This research was partially supported by Advance Smart Computing Laboratory (ASCLab) Department of Computer Science, Faculty of Science, Khon Kaen University, Thailand.\"","created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:29.000000Z"},{"paper_name":"Ensemble extreme learning machine for multi-instance learning","abstract":"© 2017 ACM.Multi-instance learning (MIL) is a classification approach for classifying on a collection of instances which each group is represented as a bag. The main task of MIL is to learn from labels and features of instances to produce a model to predict a label of a testing bag. Traditional MIL algorithms were proposed to address the MIL problem, but most of the algorithms take a large time scale for their training process since they have to computing the parameter tuning. To address the learning time problem, the multi-instance learning method based on extreme learning machine (ELM-MIL) was proposed. However, the randomly generated parameters of ELM-MIL may reduce its generalization performance. Therefore, we proposed a new method to improve the generalization performance of the ELM-MIL which the new method is based on the ensemble with majority voting approach named the ensemble extreme learning machine for multi-instance learning (E-ELM-MIL). To evaluate the new method, several benchmark datasets were studied in this paper. From experimental results show that E-ELM-MIL outperforms ELM-MIL and the other state of the art MIL algorithm.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"ACM International Conference Proceeding Series","keyword":"[{\"$\":\"Ensembles\",\"@xml:lang\":\"eng\"},{\"$\":\"Extreme learning machine\",\"@xml:lang\":\"eng\"},{\"$\":\"Majority voting\",\"@xml:lang\":\"eng\"},{\"$\":\"Multi-instance learning\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85024390990&origin=inward","publication":null,"paper_yearpub":"2017","paper_volume":"0","paper_issue":null,"paper_citation":3,"paper_page":"56-60","paper_doi":"10.1145\/3055635.3056641","paper_funder":null,"created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:28.000000Z"},{"paper_name":"Improved convex incremental extreme learning machine based on ridgelet and PSO algorithm","abstract":"© 2016 IEEE.The most difficult problem with the extreme learning machine is the selection of the hidden nodes size. The proper number of hidden nodes is predefined through a trial and error approach. The convex incremental extreme learning machine (CI-ELM) has been proposed to tackle this problem. CI-ELM is an incremental constructive neural network with universal approximation abilities. However, we have found that some hidden nodes added into a hidden layer, may play a minor role in the network, which results in an increase in network complexity. In order to avoid this shortcoming, we propose here in an improved convex incremental extreme learning machine with optimal ridgelet hidden nodes (ICOR-ELM). The proposed method uses the ridgelet function as the activation function within the hidden layer. In each step of the learning process, the optimal hidden node parameters, which are optimized through particle swarm optimization (PSO), are added to the existing hidden layer. Experimental results prove that the proposed method can achieve greater generalization performance with more compact architecture than other methods, and demonstrates faster convergence than other incremental ELM methods.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"2016 13th International Joint Conference on Computer Science and Software Engineering, JCSSE 2016","keyword":"[{\"$\":\"Convex incremental extreme learning machine\",\"@xml:lang\":\"eng\"},{\"$\":\"incremental constructive neural networks\",\"@xml:lang\":\"eng\"},{\"$\":\"particle swarm optimization\",\"@xml:lang\":\"eng\"},{\"$\":\"ridgelet function\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85006961450&origin=inward","publication":null,"paper_yearpub":"2016","paper_volume":null,"paper_issue":null,"paper_citation":4,"paper_page":null,"paper_doi":"10.1109\/jcsse.2016.7748870","paper_funder":"\"This work was supported by the Graduate Education of Computer and Information Science Research Grant from Department of Computer Science, Faculty of Science, Khon Kaen University (Grant no. 002\\\/2556).\"","created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:27.000000Z"},{"paper_name":"Extended hierarchical extreme learning machine with multilayer perceptron","abstract":"© 2016 IEEE.For learning in big datasets, the classification performance of ELM might be low due to input samples are not extracted features properly. To address this problem, the hierarchical extreme learning machine (H-ELM) framework was proposed based on the hierarchical learning architecture of multilayer perceptron. H-ELM composes of two parts; the first is the unsupervised multilayer encoding part and the second part is the supervised feature classification part. H-ELM can give higher accuracy rate than of the traditional ELM. However, it still has to enhance its classification performance. Therefore, this paper proposes a new method namely as the extending hierarchical extreme learning machine (EH-ELM). For the extended supervisor part of EH-ELM, we have got an idea from the two-layers extreme learning machine. To evaluate the performance of EH-ELM, three different image datasets; Semeion, MNIST, and NORB, were studied. The experimental results show that EH-ELM achieves better performance than of H-ELM and the other multi-layer framework.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"2016 13th International Joint Conference on Computer Science and Software Engineering, JCSSE 2016","keyword":"[{\"$\":\"Hierarchical Extreme Learning Machine\",\"@xml:lang\":\"eng\"},{\"$\":\"Hierarchical learning\",\"@xml:lang\":\"eng\"},{\"$\":\"Multilayer Perceptron\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85006954201&origin=inward","publication":null,"paper_yearpub":"2016","paper_volume":null,"paper_issue":null,"paper_citation":12,"paper_page":null,"paper_doi":"10.1109\/jcsse.2016.7748874","paper_funder":"\"This research was partially supported by the Department of Computer Science, Faculty of Science, Khon Kaen University, Thailand.\"","created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:24.000000Z"},{"paper_name":"Harmonic extreme learning machine for data clustering","abstract":"© 2016 IEEE.Unsupervised Extreme Learning Machine (US-ELM) is the one type of neural network which modified from Extreme Learning Machine (ELM) for handle the clustering problem. Nevertheless, US-ELM has problem with nonfulfillment of solution due to K-Mean algorithm was used to cluster which made the accuracy of solution was unstable when training many times. In this paper, K-Harmonic mean algorithm was proposed to instead of K-Mean algorithm to improve the accuracy of solution and more stable gained called, Harmonic Extreme Learning Machine (Harm-ELM) likewise the experiment result compared with state-of-the-art show that Harm-ELM can overcome to 75% of all datasets that used to attempt.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"2016 13th International Joint Conference on Computer Science and Software Engineering, JCSSE 2016","keyword":"[{\"$\":\"Clustering Technique\",\"@xml:lang\":\"eng\"},{\"$\":\"K-Harmonic Mean\",\"@xml:lang\":\"eng\"},{\"$\":\"Unsupervised Extreme Learning Machine (US-ELM)\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85006893186&origin=inward","publication":null,"paper_yearpub":"2016","paper_volume":null,"paper_issue":null,"paper_citation":9,"paper_page":null,"paper_doi":"10.1109\/jcsse.2016.7748872","paper_funder":null,"created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:25.000000Z"},{"paper_name":"Improvement flower pollination extreme learning machine based on meta-learning","abstract":"© 2016 IEEE.Extreme Learning Machine (ELM) model which learn very faster than other neural networks model but the solution was not suitable as expected since the randomness of the input weights and biases may cause to the nonfulfillment of solution. Flower Pollination Extreme Learning Machine (FP-ELM) model that it was merged by ELM and Flower Pollination Algorithm (FPA) to adjust the input weight and biases for improve performance of output weight when the input weight and biases were calculated. Nonetheless, FP-ELM may cause overfitting and more number of hidden nodes were used. In this paper, Meta Learning of Flower Pollination Extreme Learning Machine (Meta-FPELM) was proposed that compart the input weight, calculate to hidden nodes as FP-ELM and combine to the last output weight. In addition, the result of real word regression problems experiment of Meta-FPELM compared with state-of-the-art show that Meta-FPELM can overcome five-eighth in testing phase for all datasets.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"2016 13th International Joint Conference on Computer Science and Software Engineering, JCSSE 2016","keyword":"[{\"$\":\"Extreme Learning Machine (ELM)\",\"@xml:lang\":\"eng\"},{\"$\":\"Flower Pollination Algorithm (FPA)\",\"@xml:lang\":\"eng\"},{\"$\":\"Flower Pollination Extreme Learning Machine (FP-ELM)\",\"@xml:lang\":\"eng\"},{\"$\":\"Meta-Learning Extreme Learning Machine (Meta-ELM)\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=85006877782&origin=inward","publication":null,"paper_yearpub":"2016","paper_volume":null,"paper_issue":null,"paper_citation":6,"paper_page":null,"paper_doi":"10.1109\/jcsse.2016.7748871","paper_funder":null,"created_at":"2025-03-08T15:46:16.000000Z","updated_at":"2025-03-08T15:46:27.000000Z"},{"paper_name":"Enhancement of online sequential extreme learning machine based on the householder block exact inverse QRD recursive least squares","abstract":"© 2014 Elsevier B.V.The online sequential extreme learning machine (OS-ELM) has been used for training without retraining the ELM when a chunk of data is received. However, OS-ELM may be affected by an improper number of hidden nodes settings which reduces the generalization of OS-ELM. This paper addresses this problem in OS-ELM. A new structural tolerance OS-ELM (STOS-ELM), based on the Householder block exact inverse QRD recursive least squares algorithm having numerical robustness is proposed. Experimental results conducted on four regressions and five classification problems showed that STOS-ELM can handle the situation when the network is constructed with an improper number of hidden nodes. Accordingly, the proposed STOS-ELM can be easily applied; the size of the hidden layer of ELM can be roughly approximated. If a chunk of data is received, it can be updated in the existing network without having to worry about the proper number of given hidden nodes. Furthermore, the accuracy of the network trained by STOS-ELM is comparable to that of the batch ELM when the networks have the same configurations. STOS-ELM can also be applied in ensemble version (ESTOS-ELM). We found that the stability of STOS-ELM can be further improved using the ensemble technique. The results show that ESTOS-ELM is also more stable and accurate than both of the original OS-ELM and EOS-ELM, especially in the classification problems.","paper_type":"Journal","paper_subtype":"Article","paper_sourcetitle":"Neurocomputing","keyword":"[{\"$\":\"Ensemble\",\"@xml:lang\":\"eng\"},{\"$\":\"Extreme learning machine\",\"@xml:lang\":\"eng\"},{\"$\":\"Householder block exact inverse QR decomposition\",\"@xml:lang\":\"eng\"},{\"$\":\"Online sequential extreme learning machine\",\"@xml:lang\":\"eng\"},{\"$\":\"Robustness\",\"@xml:lang\":\"eng\"},{\"$\":\"Structural tolerance\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=84922016664&origin=inward","publication":null,"paper_yearpub":"2015","paper_volume":"149","paper_issue":"Part A","paper_citation":10,"paper_page":"239-252","paper_doi":"10.1016\/j.neucom.2013.10.047","paper_funder":null,"created_at":"2025-03-08T15:46:17.000000Z","updated_at":"2025-03-08T15:46:25.000000Z"},{"paper_name":"Evolutionary circular-ELM for the reduced-reference assessment of perceived image quality","abstract":"© Springer-Verlag Berlin Heidelberg 2015.At present, the quality of the image is very important. The audience needs to get the undistorted image like the original image. Cause of the loss of image quality such as storage, transmission, compression and rendering. The mechanisms rely on systems that can assess the visual quality with human perception are required. Computational Intelligence (CI) paradigms represent a suitable technology to solve this challenging problem. In this paper present, the Evolutionary Extreme Learning Machine (EC-ELM) is derived into Circular-ELM (C-ELM) that is an extended Extreme Learning Machine (ELM) and the Differential Evolution (DE) to select appropriate weights and hidden biases, which can proves performance in addressing the visual quality assessment problem by embedded in the proposed framework. The experimental results, the EC-ELM can map the visual signals into quality score values that close to the real quality score than ELM, Evolutionary Extreme Learning (E-ELM) and the original C-ELM and also stable as well. Its can confirms that the EC-ELM is proved on recognized benchmarks and for four different types of distortions.","paper_type":"Book Series","paper_subtype":"Article","paper_sourcetitle":"Lecture Notes in Electrical Engineering","keyword":null,"paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=84923135822&origin=inward","publication":null,"paper_yearpub":"2015","paper_volume":"339","paper_issue":null,"paper_citation":9,"paper_page":"657-664","paper_doi":"10.1007\/978-3-662-46578-3_77","paper_funder":null,"created_at":"2025-03-08T15:46:17.000000Z","updated_at":"2025-03-08T15:46:26.000000Z"},{"paper_name":"License plate recognition application using extreme learning machines","abstract":"© 2014 IEEE.Recording a car license plate is an important task for police officers or security officers to check the car of interest. However, manually recording these plates comes with problems. It is easy to make a mistake, or it can be lost. The Extreme Learning Machine (ELM) can classify the plates faster and it is a more accurate system. Therefore, this paper proposes a new license plate recognition system using ELM. The proposed system is composed of two parts: the first is a mobile application to take a picture of the car license plate, and the second is the recognition system using ELM. The recognition system entails two parts: the first is to preprocess and extract features using the histogram of oriented gradients (HOG). The second part is to classify each number and each of the Thai alphabet letters that appear on the car license plates. Also, the system will classify provinces of each plate. The results of the experiment show that the testing recognition rate when trained with 200 hidden nodes is 89.05% while the rate of correctly recognized plates is 252 out of 283 plates.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"Proceedings of the 2014 3rd ICT International Senior Project Conference, ICT-ISPC 2014","keyword":"[{\"$\":\"ELM\",\"@xml:lang\":\"eng\"},{\"$\":\"Extreme Learning Machine\",\"@xml:lang\":\"eng\"},{\"$\":\"License Plate Recognition\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=84911366210&origin=inward","publication":null,"paper_yearpub":"2014","paper_volume":null,"paper_issue":null,"paper_citation":29,"paper_page":"103-106","paper_doi":"10.1109\/ict-ispc.2014.6923228","paper_funder":null,"created_at":"2025-03-08T15:46:17.000000Z","updated_at":"2025-03-09T11:00:00.000000Z"},{"paper_name":"Multi-label classification with extreme learning machine","abstract":"Extreme learning machine (ELM) is a well-known algorithm for single layer feedforward neural networks (SLFNs) and their learning speed is faster than traditional gradient-based neural networks. However, many of the tasks that ELM focuses on are single-label, where an instance of the input set is associated with one label. This paper proposes a new method for training ELM that will be capable of multi-label classification using the Canonical Correlation Analysis (CCA). The new method is named CCA-ELM. There are 4 steps in the training process: the first step is to compute any correlations between the input features and the set of labels using CCA, the second step maps the input space and label space to the new space, the third step uses ELM to classify and the last step is to map to the original input space. The experimental results show that CCA-ELM can improve ELM for classification on multi-label learning and its recognition performances are better than the other comparative algorithms that use the same standard CCA. © 2013 IEEE.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"Proceedings of the 2014 6th International Conference on Knowledge and Smart Technology, KST 2014","keyword":"[{\"$\":\"Canonical correlation analysis\",\"@xml:lang\":\"eng\"},{\"$\":\"Extreme learning machine\",\"@xml:lang\":\"eng\"},{\"$\":\"Multi-label classification\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=84902499857&origin=inward","publication":null,"paper_yearpub":"2014","paper_volume":null,"paper_issue":null,"paper_citation":26,"paper_page":"81-86","paper_doi":"10.1109\/kst.2014.6775398","paper_funder":null,"created_at":"2025-03-08T15:46:17.000000Z","updated_at":"2025-03-08T15:46:23.000000Z"},{"paper_name":"Handwritten character recognition using histograms of oriented gradient features in deep learning of artificial neural network","abstract":"Feature extraction plays an essential role in hand written character recognition because of its effect on the capability of classifiers. This paper presents a framework for investigating and comparing the recognition ability of two classifiers: Deep-Learning Feedforward-Backpropagation Neural Network (DFBNN) and Extreme Learning Machine (ELM). Three data sets: Thai handwritten characters, Bangla handwritten numerals, and Devanagari handwritten numerals were studied. Each data set was divided into two categories: non-extracted and extracted features by Histograms of Oriented Gradients (HOG). The experimental results showed that using HOG to extract features can improve recognition rates of both of DFBNN and ELM. Furthermore, DFBNN provides higher slightly recognition rates than those of ELM. © 2013 IEEE.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"2013 International Conference on IT Convergence and Security, ICITCS 2013","keyword":"[{\"$\":\"Deep learning neural network\",\"@xml:lang\":\"eng\"},{\"$\":\"Extreme learning machine\",\"@xml:lang\":\"eng\"},{\"$\":\"Feature extraction\",\"@xml:lang\":\"eng\"},{\"$\":\"Handwritten character recognition\",\"@xml:lang\":\"eng\"},{\"$\":\"Histograms of oriented gradients\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=84894186954&origin=inward","publication":null,"paper_yearpub":"2013","paper_volume":null,"paper_issue":null,"paper_citation":61,"paper_page":null,"paper_doi":"10.1109\/icitcs.2013.6717840","paper_funder":null,"created_at":"2025-03-08T15:46:17.000000Z","updated_at":"2025-03-08T15:46:20.000000Z"},{"paper_name":"Evolutionary circular extreme learning machine","abstract":"Circular Extreme Learning Machine (C-ELM) is an extension of Extreme Learning Machine. Its power is mapping both linear and circular separation boundaries. However, C-ELM uses the random determination of the input weights and hidden biases, which may lead to local optimal. This paper proposes a hybrid learning algorithms based on the C-ELM and the Differential Evolution (DE) to select appropriate weights and hidden biases. It called Evolutionary circular extreme learning machine (EC-ELM). From experimental results show EC-ELM can slightly improve C-ELM and also reduce the number of nodes network. © 2013 IEEE.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"2013 International Computer Science and Engineering Conference, ICSEC 2013","keyword":"[{\"$\":\"Circular Extreme Learning Machine\",\"@xml:lang\":\"eng\"},{\"$\":\"Differential Evolution\",\"@xml:lang\":\"eng\"},{\"$\":\"Extreme learning machine\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=84893543645&origin=inward","publication":null,"paper_yearpub":"2013","paper_volume":null,"paper_issue":null,"paper_citation":7,"paper_page":"292-297","paper_doi":"10.1109\/icsec.2013.6694796","paper_funder":null,"created_at":"2025-03-08T15:46:17.000000Z","updated_at":"2025-03-08T15:46:26.000000Z"},{"paper_name":"Robust extreme learning machine","abstract":"The output weights computing of extreme learning machine (ELM) encounters two problems, the computational and outlier robustness problems. The computational problem occurs when the hidden layer output matrix is a not full column rank matrix or an ill-conditioned matrix because of randomly generated input weights and biases. An existing solution to this problem is Singular Value Decomposition (SVD) method. However, the training speed is still affected by the large complexity of SVD when computing the Moore-Penrose (MP) pseudo inverse. The outlier robustness problem may occur when the training data set contaminated with outliers then the accuracy rate of ELM is extremely affected. This paper proposes the Extended Complete Orthogonal Decomposition (ECOD) method to solve the computational problem in ELM weights computing via ECODLS algorithm. And the paper also proposes the other three algorithms, i.e. the iteratively reweighted least squares (IRWLS-ELM), ELM based on the multivariate least-trimmed squares (MLTS-ELM), and ELM based on the one-step reweighted MLTS (RMLTS-ELM) to solve the outlier robustness problem. However, they also encounter the computational problem. Therefore, the ECOD via ECODLS algorithm is also used successfully in the three proposed algorithms. The experiments of regression problems were conducted on both toy and real-world data sets. The outlier types are one-sided and two-sided outliers. Each experiment was randomly contaminated with outliers, of one type only, with 10%, 20%, 30%, 40%, and 50% of the total training data size. Meta-metrics evaluation was used to measure the outlier robustness of the proposed algorithms compared to the existing algorithms, i.e. the minimax probability machine regression (MPMR) and the ordinary ELM. The experimental results showed that ECOD can effectively replace SVD. The ECOD is robust to the not full column rank or the ill-conditional problem. The speed of the ELM training using ECOD is also faster than the ordinary training algorithm. Moreover, the meta-metrics measure showed that the proposed algorithms are less affected by the increasing number of outliers than the existing algorithms. © 2012 Elsevier B.V.","paper_type":"Journal","paper_subtype":"Article","paper_sourcetitle":"Neurocomputing","keyword":"[{\"$\":\"Extended Complete Orthogonal Decomposition\",\"@xml:lang\":\"eng\"},{\"$\":\"Extreme learning machine\",\"@xml:lang\":\"eng\"},{\"$\":\"Iteratively reweighted least squares\",\"@xml:lang\":\"eng\"},{\"$\":\"Meta-metrics evaluation\",\"@xml:lang\":\"eng\"},{\"$\":\"Minimax probability machine regression\",\"@xml:lang\":\"eng\"},{\"$\":\"Moore-Penrose pseudo inverse\",\"@xml:lang\":\"eng\"},{\"$\":\"Multivariate least-trimmed squares\",\"@xml:lang\":\"eng\"},{\"$\":\"Outlier\",\"@xml:lang\":\"eng\"},{\"$\":\"Robustness\",\"@xml:lang\":\"eng\"},{\"$\":\"Singular Value Decomposition\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=84870248640&origin=inward","publication":null,"paper_yearpub":"2013","paper_volume":"102","paper_issue":null,"paper_citation":195,"paper_page":"31-44","paper_doi":"10.1016\/j.neucom.2011.12.045","paper_funder":"\"This work was partially supported by the Higher Education Research Promotion and National Research University Project of Thailand , Office of the Higher Education Commission , through the Cluster of Research to Enhance the Quality of Basic Education and Department of Computer Science, Faculty of Science, Khon Kaen University . This research is a part of the Computational Science Research Group (COSRG), Faculty of Science, Khon Kaen University (COSRG-SCKKU). We would also thank Mr. James McCloskey for proofreading the manuscript of this paper. KSN would like to thank Prof. C. Lursinsap of AVIC for the discussion.\"","created_at":"2025-03-08T15:46:17.000000Z","updated_at":"2025-03-08T15:46:20.000000Z"},{"paper_name":"A comparative study of pseudo-inverse computing for the extreme learning machine classifier","abstract":"Most feed-forward artificial neural network training algorithms for classification problems are based on an iterative steepest descent technique. Their well-known drawback is slow convergence. A fast solution is an Extreme Learning Machine (ELM) computing the Moore-Penrose inverse using SVD. However, the most significant training time is pseudo-inverse computing. Thus, this paper proposes two fast solutions to pseudo-inverse computing based on QR with pivoting and Fast General Inverse algorithms. They are QR-ELM and GENINV-ELM, respectively. The benchmarks are conducted on 5 standard classification problems, i.e., diabetes, satellite images, image segmentation, forest cover type and sensit vehicle (combined) problems. The experimental results clearly showed that both QR-ELM and GENINV-ELM can speed up the training time of ELM and the quality of their solutions can be compared to that of the original ELM. They also show that QR-ELM is more robust than GENINV-ELM. © 2011 AICIT.","paper_type":"Conference Proceeding","paper_subtype":"Conference Paper","paper_sourcetitle":"Proceedings - 3rd International Conference on Data Mining and Intelligent Information Technology Applications, ICMIA 2011","keyword":"[{\"$\":\"Cholesky decomposition\",\"@xml:lang\":\"eng\"},{\"$\":\"Extreme Learning Machine (ELM)\",\"@xml:lang\":\"eng\"},{\"$\":\"Matrix decomposition\",\"@xml:lang\":\"eng\"},{\"$\":\"Moore-Penrose generalized inverse\",\"@xml:lang\":\"eng\"},{\"$\":\"QR decomposition\",\"@xml:lang\":\"eng\"},{\"$\":\"Single layer feed-forward neural network\",\"@xml:lang\":\"eng\"},{\"$\":\"Singular Value Decomposition (SVD)\",\"@xml:lang\":\"eng\"}]","paper_url":"https:\/\/www.scopus.com\/inward\/record.uri?partnerID=HzOxMe3b&scp=84855833197&origin=inward","publication":null,"paper_yearpub":"2011","paper_volume":null,"paper_issue":null,"paper_citation":14,"paper_page":"40-45","paper_doi":null,"paper_funder":null,"created_at":"2025-03-08T15:46:17.000000Z","updated_at":"2025-03-08T15:46:24.000000Z"},{"paper_name":"Class Diagrams in UML","abstract":null,"paper_type":"Journal","paper_subtype":null,"paper_sourcetitle":"KKU Science Journal","keyword":null,"paper_url":null,"publication":null,"paper_yearpub":"2006","paper_volume":"34","paper_issue":null,"paper_citation":0,"paper_page":"171-182","paper_doi":null,"paper_funder":null,"created_at":"2025-03-08T15:46:19.000000Z","updated_at":"2025-03-08T15:46:19.000000Z"},{"paper_name":"กระบวนทัศน์การเขียนโปรแกรมเชิงคำสั่งและเชิงวัตถุ","abstract":null,"paper_type":"Journal","paper_subtype":null,"paper_sourcetitle":"KKU Science Journal","keyword":null,"paper_url":null,"publication":null,"paper_yearpub":"2004","paper_volume":"32","paper_issue":null,"paper_citation":0,"paper_page":"143-149","paper_doi":null,"paper_funder":null,"created_at":"2025-03-08T15:46:19.000000Z","updated_at":"2025-03-08T15:46:19.000000Z"},{"paper_name":"Improving butterfly family classification using past separating features extraction in extreme learning machine","abstract":null,"paper_type":null,"paper_subtype":null,"paper_sourcetitle":"Proceedings of the 2nd International Conference on Intelligent Systems and …, 2014","keyword":null,"paper_url":"https:\/\/scholar.google.com\/citations?view_op=view_citation&hl=en&user=00JXDiUAAAAJ&pagesize=100&citation_for_view=00JXDiUAAAAJ:4JMBOYKVnBMC","publication":null,"paper_yearpub":"2014","paper_volume":null,"paper_issue":null,"paper_citation":5,"paper_page":null,"paper_doi":null,"paper_funder":null,"created_at":"2025-03-08T15:46:27.000000Z","updated_at":"2025-03-08T15:46:27.000000Z"},{"paper_name":"Applying regularization least squares canonical correlation analysis in extreme learning machine for multi-label classification problems","abstract":null,"paper_type":null,"paper_subtype":null,"paper_sourcetitle":"Proceedings of ELM-2014 Volume 1: Algorithms and Theories, 377-396, 2015","keyword":null,"paper_url":"https:\/\/scholar.google.com\/citations?view_op=view_citation&hl=en&user=00JXDiUAAAAJ&pagesize=100&citation_for_view=00JXDiUAAAAJ:_Qo2XoVZTnwC","publication":null,"paper_yearpub":"2015","paper_volume":null,"paper_issue":null,"paper_citation":4,"paper_page":null,"paper_doi":null,"paper_funder":null,"created_at":"2025-03-08T15:46:28.000000Z","updated_at":"2025-03-08T15:46:28.000000Z"}]